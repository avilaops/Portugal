# Avila ML ğŸš€

[![Crates.io](https://img.shields.io/crates/v/avila-ml)](https://crates.io/crates/avila-ml)
[![Documentation](https://docs.rs/avila-ml/badge.svg)](https://docs.rs/avila-ml)
[![License](https://img.shields.io/badge/license-MIT%2FApache--2.0-blue)](LICENSE-MIT)
[![Build Status](https://img.shields.io/badge/build-passing-brightgreen)](https://github.com/avilaops/arxis)

**High-performance Machine Learning library for scientific computing, built in pure Rust. 100% native, zero Python dependencies.**

Avila ML is a production-ready machine learning framework designed for **scientific applications**, with native support for **4D convolutions** (spacetime data), **automatic differentiation**, and **parallel computing**. Built by [Avila Cloud](https://avila.cloud) ğŸ‡§ğŸ‡·

## âœ¨ Features

- ğŸ”¥ **Autograd**: Complete automatic differentiation with computational graph (validated with gradient checking)
- ğŸ§  **Neural Networks**: Linear, Conv2d, **Conv4d** (unique for spacetime scientific data)
- ğŸ¯ **Optimizers**: SGD, Adam, AdamW, RMSprop with learning rate schedulers
- ğŸ“Š **Loss Functions**: MSE, Cross Entropy, BCE, Huber, Smooth L1
- ğŸ”„ **Data Loading**: Dataset, DataLoader with batching and shuffling
- ğŸŒŸ **Attention**: Self-attention, Multi-head attention for Transformers
- ğŸ§ª **Scientific Computing**: Conv4d for astrophysical/climate/medical data
- âš¡ **Performance**: Rayon parallelization, optimized for multi-core CPUs
- ğŸ¦€ **Pure Rust**: No Python dependencies, type-safe, memory-safe
- âœ… **Production Ready**: 30+ unit tests, 7 gradient tests, all passing

## ğŸš€ Quick Start

```toml
[dependencies]
avila-ml = "1.0"
ndarray = "0.16"
```

### Simple Neural Network

```rust
use avila_ml::prelude::*;
use avila_ml::tensor::{Tensor, TensorLike};
use ndarray::ArrayD;

// Create tensors with autograd
let x = Tensor::new(ArrayD::from_elem(ndarray::IxDyn(&[1, 784]), 0.5_f32)).requires_grad_();

// Build a neural network
let linear1 = Linear::new(784, 128);
let relu = ReLU::new();
let linear2 = Linear::new(128, 10);

// Forward pass
let h = linear1.forward(&x);
let h = relu.forward(&h);
let output = linear2.forward(&h);

// Backward pass (automatic differentiation)
let mut loss = output.mean();
loss.backward();

// Optimizer step
let mut optimizer = Adam::new(vec![&linear1.weight, &linear2.weight], 0.001);
optimizer.step();
```

### 4D Convolution for Gravitational Wave Detection

```rust
use avila_ml::nn::Conv4d;
use avila_ml::tensor::Tensor;
use ndarray::ArrayD;

// LIGO/LISA gravitational wave data: (batch, channels, time, x, y, z)
let input = Tensor::new(ArrayD::from_shape_fn(
    ndarray::IxDyn(&[1, 3, 16, 8, 8, 8]),
    |_| rand::random::<f32>()
));

// 4D convolution - unique to Avila ML!
let conv4d = Conv4d::new(
    3,           // input channels (h+, hx, frequency)
    16,          // output channels
    (3, 3, 3, 3) // kernel size (t, x, y, z)
);

let output = conv4d.forward(&input);
println!("Detected spacetime patterns: {:?}", output.shape());
// Output: [1, 16, 14, 6, 6, 6] - learned features in 4D spacetime
```

## âœ… Production Quality

**All tests passing:**
- âœ… 30 unit tests (tensor, layers, optimizers)
- âœ… 7 gradient checking tests (validates mathematical correctness)
- âœ… 4 working examples (regression, MNIST, Conv4d, LIGO)
- âœ… Doctests validated
- âœ… Release build optimized (LTO, codegen-units=1)

## ğŸ“¦ Architecture

```
avila-ml/
â”œâ”€â”€ tensor.rs        # Tensor with autograd support
â”œâ”€â”€ autograd.rs      # Backward propagation engine
â”œâ”€â”€ nn/
â”‚   â”œâ”€â”€ mod.rs       # Linear, Conv2d, Conv4d, Sequential
â”‚   â”œâ”€â”€ activation.rs # ReLU, Sigmoid, Tanh, Softmax, GELU
â”‚   â”œâ”€â”€ normalization.rs # BatchNorm, LayerNorm, Dropout
â”‚   â””â”€â”€ attention.rs # Attention, MultiHeadAttention, Transformer
â”œâ”€â”€ optim.rs         # SGD, Adam, AdamW, RMSprop
â”œâ”€â”€ loss.rs          # MSE, CrossEntropy, BCE, Huber
â”œâ”€â”€ data.rs          # Dataset, DataLoader
â””â”€â”€ utils.rs         # Initialization, schedulers, early stopping
```

## ğŸ§ª Examples

### Linear Regression

```bash
cargo run --example linear_regression
```

### MNIST Classification

```bash
cargo run --example mnist_training
```

### Gravitational Wave Detection (4D Conv)

```bash
cargo run --example conv4d_astrophysics
```

## ğŸ¯ Use Cases

### Scientific Computing
- ğŸŒŒ **Gravitational wave detection** (LIGO, LISA)
- ğŸŒ **Climate modeling** (3D space + time)
- ğŸ§¬ **Medical imaging** (CT/MRI sequences)
- âš›ï¸ **Particle physics** (detector events)
- ğŸŒŠ **Fluid dynamics** simulations

### General ML
- ğŸ“¸ Image classification (MNIST, CIFAR)
- ğŸ’¬ Natural language processing (transformers)
- ğŸ® Reinforcement learning
- ğŸ“Š Time series forecasting
- ğŸ” Anomaly detection

## ğŸ†š Comparisons

### Avila ML vs. PyTorch/TensorFlow
- âœ… **Pure Rust** - No Python runtime, better deployment
- âœ… **Memory safe** - No segfaults, guaranteed by Rust
- âœ… **Conv4d native** - Built for scientific data
- âœ… **Lightweight** - No heavy dependencies
- âš ï¸ **Early stage** - Ecosystem still growing

### Avila ML vs. Other Rust ML Libraries
- âœ… **Conv4d support** - Unique for 4D spacetime data
- âœ… **Full autograd** - Like PyTorch, but in Rust
- âœ… **Scientific focus** - Optimized for research
- âœ… **Modern API** - Ergonomic and type-safe

## ğŸ—ºï¸ Roadmap

### âœ… Version 1.0 (Production Ready)
- [x] Tensor with autograd (Arc<Mutex> gradient sharing)
- [x] Complete backward propagation engine
- [x] Gradient checking (7 tests validating correctness)
- [x] Linear, Conv2d, Conv4d layers
- [x] Activation functions (ReLU, Sigmoid, Tanh, Softmax)
- [x] Optimizers (SGD, Adam, AdamW, RMSprop)
- [x] Loss functions (MSE, CrossEntropy, BCE, Huber)
- [x] DataLoader with batching
- [x] Attention mechanisms
- [x] Conv4d for scientific data (parallelized with Rayon)
- [x] Examples: MNIST, Linear Regression, LIGO/LISA

### ğŸš§ Version 1.1 (Performance)
- [ ] FFT-based convolutions for large kernels
- [ ] im2col optimization for Conv2d
- [ ] BLAS integration for matrix operations
- [ ] Benchmarking suite

### ğŸ”® Version 2.0 (GPU & Advanced)
- [ ] GPU acceleration (CUDA/ROCm via wgpu)
- [ ] Model serialization (save/load with serde)
- [ ] Distributed training
- [ ] Mixed precision (f16/bf16)
- [ ] Advanced architectures (ResNet, Vision Transformer)
- [ ] Integration with AvilaDB for ML pipelines

## ğŸ¤ Contributing

We welcome contributions! Priority areas:

**High Priority:**
- GPU support (CUDA/ROCm via wgpu or cudarc)
- FFT-based convolutions for performance
- Model serialization (saving/loading trained models)
- More examples and tutorials

**Medium Priority:**
- BLAS integration for faster matrix operations
- Benchmark suite comparing with PyTorch
- Documentation improvements
- Advanced architectures (ResNet, ViT, BERT)

**Getting Started:**
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes (ensure tests pass: `cargo test --release`)
4. Commit your changes (`git commit -m 'Add amazing feature'`)
5. Push to the branch (`git push origin feature/amazing-feature`)
6. Open a Pull Request

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

## ğŸ“š Resources

- [Documentation](https://docs.rs/avila-ml)
- [Examples](./examples)
- [Arxis Physics Engine](https://github.com/avilaops/arxis)
- [Avila Cloud Platform](https://avila.cloud)

## ğŸ“„ License

Licensed under either of:
- Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE))
- MIT License ([LICENSE-MIT](LICENSE-MIT))

at your option.

## ğŸ‡§ğŸ‡· Made in Brazil

Built with â¤ï¸ by [Avila Cloud](https://avila.cloud) - Infrastructure for Brazilian developers.

**Avila ML v1.0** - Machine Learning genuÃ­no do Brasil! ğŸš€

---

### Related Projects
- **[AvilaDB](https://docs.avila.cloud/aviladb)** - Distributed NoSQL database with 4MB documents and vector search
- **[Arxis](https://github.com/avilaops/arxis)** - Physics engine for scientific simulations
- **[AVL Platform](https://avila.cloud)** - Cloud platform built for Brazil and LATAM
