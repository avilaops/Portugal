# avila-linalg - Roadmap T√©cnico Detalhado

## v0.2.0 - Decomposi√ß√µes Fundamentais (Pr√≥xima Release)

### 1. SVD (Singular Value Decomposition) - PRIORIDADE ALTA

**Objetivo:** Decompor matriz M (m√ón) em U Œ£ V^T

**Algoritmo a Implementar:** Golub-Reinsch (two-sided Jacobi como alternativa)

**Estrutura:**
```rust
pub struct SVD<T> {
    pub u: MatrixMxN<T>,           // m√óm (ou m√ómin(m,n) vers√£o thin)
    pub singular_values: Vec<T>,   // min(m,n) valores singulares
    pub vt: MatrixMxN<T>,          // n√ón (ou min(m,n)√ón vers√£o thin)
}

impl<T: Float> MatrixMxN<T> {
    pub fn svd(&self) -> SVD<T> {
        // Implementa√ß√£o Golub-Reinsch
    }

    pub fn svd_thin(&self) -> SVD<T> {
        // Vers√£o econ√¥mica (mais eficiente)
    }
}
```

**Passos:**
1. Bidiagonaliza√ß√£o (via Householder reflections)
2. Diagonaliza√ß√£o iterativa (Givens rotations)
3. Converg√™ncia quando off-diagonal < epsilon

**Testes:**
- [ ] Matriz 3√ó3 conhecida
- [ ] Matriz 5√ó3 (tall)
- [ ] Matriz 3√ó5 (wide)
- [ ] Reconstru√ß√£o: M = U Œ£ V^T
- [ ] Valores singulares em ordem decrescente

**Aplica√ß√µes:**
- PCA (an√°lise de componentes principais)
- Pseudoinversa (Moore-Penrose)
- Compress√£o de imagens
- Sistemas least-squares

---

### 2. Eigenvalues/Eigenvectors - PRIORIDADE ALTA

**Objetivo:** Encontrar Œª e v tais que Av = Œªv

**Algoritmos a Implementar:**

#### 2.1. Power Iteration (mais simples)
```rust
impl<T: Float> Matrix3x3<T> {
    pub fn dominant_eigenvalue(&self, max_iter: usize) -> (T, Vector3<T>) {
        // Retorna maior eigenvalue e seu eigenvector
    }
}
```

#### 2.2. QR Algorithm (mais completo)
```rust
pub struct EigenDecomposition<T> {
    pub eigenvalues: Vec<T>,
    pub eigenvectors: MatrixMxN<T>,  // Cada coluna √© um eigenvector
}

impl<T: Float> MatrixMxN<T> {
    pub fn eigen(&self) -> EigenDecomposition<T> {
        // QR Algorithm com shifts
    }
}
```

**Passos (QR Algorithm):**
1. Reduzir a forma Hessenberg (Householder)
2. Iterar: A_k = Q_k R_k, A_{k+1} = R_k Q_k
3. Converg√™ncia quando triangular superior
4. Eigenvalues na diagonal

**Testes:**
- [ ] Matriz identidade (eigenvalues = 1, 1, 1)
- [ ] Matriz diagonal (eigenvalues = valores diagonais)
- [ ] Matriz sim√©trica 3√ó3
- [ ] Verificar: A v_i = Œª_i v_i

**Aplica√ß√µes:**
- PCA
- An√°lise de estabilidade
- F√≠sica qu√¢ntica
- Processamento de sinais

---

### 3. QR Decomposition - PRIORIDADE M√âDIA

**Objetivo:** Decompor M = QR (Q ortogonal, R triangular superior)

**Algoritmos:**

#### 3.1. Gram-Schmidt (mais simples)
```rust
pub struct QR<T> {
    pub q: MatrixMxN<T>,  // Matriz ortogonal
    pub r: MatrixMxN<T>,  // Triangular superior
}

impl<T: Float> MatrixMxN<T> {
    pub fn qr(&self) -> QR<T> {
        // Gram-Schmidt modificado (mais est√°vel)
    }
}
```

#### 3.2. Householder Reflections (mais est√°vel)
```rust
impl<T: Float> MatrixMxN<T> {
    pub fn qr_householder(&self) -> QR<T> {
        // Mais est√°vel numericamente
    }
}
```

**Testes:**
- [ ] Matriz 3√ó3
- [ ] Verificar Q^T Q = I (ortogonalidade)
- [ ] Verificar M = QR
- [ ] R √© triangular superior

**Aplica√ß√µes:**
- Resolver sistemas lineares
- Implementar eigenvalue algorithm
- Least squares

---

### 4. Opera√ß√µes Matriciais Adicionais

#### 4.1. Inversa de Matrix4x4
```rust
impl<T: Float> Matrix4x4<T> {
    pub fn inverse(&self) -> Option<Self> {
        // Via adjunta (similar a 3√ó3)
        // Ou via Gauss-Jordan
    }
}
```

#### 4.2. Resolver Sistemas Lineares
```rust
impl<T: Float> MatrixMxN<T> {
    /// Resolve Ax = b
    pub fn solve(&self, b: &[T]) -> Option<Vec<T>> {
        // Via LU decomposition ou QR
    }
}
```

**Testes:**
- [ ] Sistema 3√ó3 com solu√ß√£o √∫nica
- [ ] Sistema inconsistente (sem solu√ß√£o)
- [ ] Sistema indeterminado

---

## v0.3.0 - Performance & Otimiza√ß√µes

### 1. Paraleliza√ß√£o com Rayon

**Feature flag:** `parallel`

```rust
#[cfg(feature = "parallel")]
use rayon::prelude::*;

impl<T: Float + Send + Sync> MatrixMxN<T> {
    pub fn mul_parallel(&self, other: &Self) -> Self {
        // Multiplica√ß√£o paralela de matrizes
    }
}
```

**Otimiza√ß√µes:**
- [ ] Matrix multiplication paralela
- [ ] SVD paralelo (bidiagonaliza√ß√£o)
- [ ] Opera√ß√µes vetoriais em lotes

### 2. SIMD Intrinsics

**Plataformas:** x86_64 (AVX2, AVX512), ARM (NEON)

```rust
#[cfg(target_arch = "x86_64")]
use std::arch::x86_64::*;

impl Vector4<f32> {
    #[target_feature(enable = "avx2")]
    unsafe fn dot_simd(&self, other: &Self) -> f32 {
        // Produto escalar SIMD
    }
}
```

**Opera√ß√µes SIMD:**
- [ ] Dot product (4 floats paralelos)
- [ ] Matrix √ó Vector (4√ó4)
- [ ] Normalize (via rsqrt)

### 3. Benchmarks

```rust
// benches/matrix_ops.rs
use criterion::{black_box, criterion_group, criterion_main, Criterion};
use avila_linalg::{Matrix3x3, MatrixMxN};

fn bench_matrix_multiply(c: &mut Criterion) {
    let m1 = Matrix3x3::identity();
    let m2 = Matrix3x3::identity();

    c.bench_function("matrix3x3_mul", |b| {
        b.iter(|| black_box(m1 * m2))
    });
}
```

**Benchmarks a Criar:**
- [ ] Vector operations (dot, cross, norm)
- [ ] Matrix multiplication (3√ó3, 4√ó4, 100√ó100)
- [ ] SVD (diferentes tamanhos)
- [ ] Eigenvalues

---

## v0.4.0 - Integra√ß√£o & Valida√ß√£o

### 1. Substituir nalgebra no facial-recognition

**Arquivos a Modificar:**
- `optics.rs`: Vector3, Matrix3x3
- `geometry.rs`: Matrix operations
- `features.rs`: Convolu√ß√£o matricial
- `recognition.rs`: **PCA com nosso SVD!**

**Mudan√ßas Cr√≠ticas:**
```rust
// Antes (nalgebra)
use nalgebra::{DMatrix, DVector};
let svd = covariance_matrix.svd(true, true);

// Depois (avila-linalg)
use avila_linalg::MatrixMxN;
let svd = covariance_matrix.svd();
let eigenfaces = svd.u;  // Componentes principais
```

### 2. Valida√ß√£o com Dados Reais

**Datasets:**
- [ ] AT&T Face Database (400 imagens)
- [ ] LFW (Labeled Faces in the Wild)
- [ ] Synthetic data (varia√ß√µes controladas)

**M√©tricas:**
- [ ] Precis√£o do reconhecimento
- [ ] Tempo de treinamento
- [ ] Tempo de infer√™ncia
- [ ] Uso de mem√≥ria

### 3. Compara√ß√£o de Performance

| Opera√ß√£o          | avila-linalg | nalgebra | ndarray |
| ----------------- | ------------ | -------- | ------- |
| Matrix 3√ó3 mul    | ?            | ?        | ?       |
| SVD 100√ó100       | ?            | ?        | ?       |
| Eigenvalues 10√ó10 | ?            | ?        | ?       |
| Memory usage      | ?            | ?        | ?       |

---

## v0.5.0 - Decomposi√ß√µes Avan√ßadas

### 1. LU Decomposition
```rust
pub struct LU<T> {
    pub l: MatrixMxN<T>,  // Lower triangular
    pub u: MatrixMxN<T>,  // Upper triangular
    pub p: Vec<usize>,    // Permutation vector
}
```

### 2. Cholesky Decomposition (matrizes definidas positivas)
```rust
impl<T: Float> MatrixMxN<T> {
    pub fn cholesky(&self) -> Option<MatrixMxN<T>> {
        // L L^T = A
    }
}
```

### 3. Schur Decomposition
```rust
pub struct Schur<T> {
    pub q: MatrixMxN<T>,  // Ortogonal
    pub t: MatrixMxN<T>,  // Triangular
}
```

---

## v1.0.0 - Produ√ß√£o Ready

### Checklist para Release

#### Funcionalidades
- [x] Vetores 2D/3D/4D/ND
- [x] Matrizes 2√ó2, 3√ó3, 4√ó4, M√óN
- [ ] SVD
- [ ] Eigenvalues/Eigenvectors
- [ ] QR decomposition
- [ ] LU decomposition
- [ ] Inversa de matrizes (todas)
- [ ] Resolver sistemas lineares

#### Performance
- [ ] SIMD para opera√ß√µes cr√≠ticas
- [ ] Paraleliza√ß√£o com rayon
- [ ] Benchmarks completos
- [ ] Otimiza√ß√µes de cache

#### Qualidade
- [ ] Cobertura de testes > 90%
- [ ] Todos os doc tests passando
- [ ] Documenta√ß√£o completa (PT-BR)
- [ ] Exemplos para cada feature
- [ ] CI/CD configurado

#### Distribui√ß√£o
- [ ] Publicado no crates.io
- [ ] Versionamento sem√¢ntico
- [ ] Changelog.md
- [ ] API est√°vel (sem breaking changes)
- [ ] License files
- [ ] Contributing guidelines

---

## Al√©m do v1.0.0

### Poss√≠veis Features Futuras

#### 1. Matrizes Esparsas
```rust
pub struct SparseMatrix<T> {
    rows: usize,
    cols: usize,
    data: HashMap<(usize, usize), T>,  // COO format
}
```

#### 2. GPU Acceleration (via CUDA/OpenCL)
```rust
#[cfg(feature = "gpu")]
impl MatrixMxN<f32> {
    pub fn mul_gpu(&self, other: &Self) -> Self {
        // Multiplica√ß√£o na GPU
    }
}
```

#### 3. Complex Numbers
```rust
use num_complex::Complex;

type Matrix3x3c = Matrix3x3<Complex<f64>>;
```

#### 4. Automatic Differentiation (para ML)
```rust
pub struct Dual<T> {
    value: T,
    gradient: T,
}
```

#### 5. Integra√ß√£o com avila-ml
```rust
// Em avila-ml
use avila_linalg::MatrixMxN;

pub struct NeuralLayer {
    weights: MatrixMxN<f32>,
    biases: Vec<f32>,
}
```

---

## Cronograma Estimado

| Vers√£o | Features          | Prazo Estimado | Status      |
| ------ | ----------------- | -------------- | ----------- |
| v0.1.0 | Base + testes     | -              | ‚úÖ Conclu√≠do |
| v0.2.0 | SVD + Eigenvalues | 2 semanas      | üî® Pr√≥ximo   |
| v0.3.0 | Performance       | 1 semana       | üìã Planejado |
| v0.4.0 | Integra√ß√£o        | 1 semana       | üìã Planejado |
| v0.5.0 | LU/Cholesky       | 1 semana       | üìã Planejado |
| v1.0.0 | Production        | 1 semana       | üìã Planejado |

**Total:** ~6-8 semanas para v1.0.0

---

## Prioriza√ß√£o de Features

### Must Have (v1.0.0)
1. ‚úÖ Vetores e matrizes b√°sicas
2. üî® SVD
3. üî® Eigenvalues
4. üìã QR decomposition
5. üìã Resolver sistemas lineares

### Should Have (v1.x)
- LU decomposition
- Cholesky
- Performance otimizada (SIMD)
- Paraleliza√ß√£o

### Could Have (v2.x)
- Matrizes esparsas
- GPU acceleration
- Complex numbers

### Won't Have (fora de escopo)
- Symbolic math (use SymPy/Mathematica)
- Arbitrary precision (use rug crate)
- Gr√°ficos (use plotters)

---

## Decis√µes de Design

### Por que Golub-Reinsch para SVD?
‚úÖ Numericamente est√°vel
‚úÖ Amplamente validado
‚úÖ Converg√™ncia garantida
‚ùå Mais complexo que Jacobi

**Alternativa:** Jacobi SVD (mais simples, um pouco mais lento)

### Por que QR Algorithm para Eigenvalues?
‚úÖ Funciona para matrizes n√£o-sim√©tricas
‚úÖ O(n¬≥) razo√°vel
‚úÖ Pode ser paralelizado
‚ùå Requer QR decomposition primeiro

**Alternativa:** Jacobi eigenvalue (apenas sim√©tricas)

### Por que Householder para QR?
‚úÖ Mais est√°vel que Gram-Schmidt
‚úÖ Menos opera√ß√µes que Givens
‚úÖ Paraleliz√°vel
‚ùå Implementa√ß√£o mais complexa

---

## Recursos de Refer√™ncia

### Papers
- Golub & Van Loan: "Matrix Computations" (4th ed)
- Watkins: "Fundamentals of Matrix Computations"
- Trefethen & Bau: "Numerical Linear Algebra"

### Implementa√ß√µes de Refer√™ncia
- LAPACK (Fortran, gold standard)
- Eigen (C++, bem otimizado)
- nalgebra (Rust, completo)
- ndarray (Rust, arrays N-D)

### Benchmarks
- SuiteSparse Matrix Collection
- NIST Matrix Market
- Own synthetic benchmarks

---

**Autor:** N√≠colas √Åvila
**√öltima atualiza√ß√£o:** 2024
**Vers√£o do documento:** 1.0
